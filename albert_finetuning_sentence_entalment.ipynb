{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qS9dZ8F3j9J8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "from transformers import AlbertTokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GWq_IaW1GdfI"
   },
   "outputs": [],
   "source": [
    "# device = xm.xla_device()\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkpfPDS1Z8a8",
    "outputId": "fdc8e9db-3d1e-47ab-f255-aa4dcf272d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "ZDulyi-rXHQy"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('snli_1.0_train.csv')[:100000]\n",
    "val_df = pd.read_csv('snli_1.0_dev.csv')[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['gold_label'].isin(['contardiction','neutral','entailment'])]\n",
    "val_df = val_df[val_df['gold_label'].isin(['contardiction','neutral','entailment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33300, 14)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aWHuqSmJYEHT"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
    "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['gold_label','sentence1','sentence2']]\n",
    "val_df = val_df[['gold_label','sentence1','sentence2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bHpMlxVYZW9x"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import os\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "class MNLIDataAlbert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df):\n",
    "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "\n",
    "    self.base_path = '/content/'\n",
    "    self.tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    self.train_data = self.load_data(self.train_df)\n",
    "    self.val_data = self.load_data(self.val_df)\n",
    "\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['sentence1'].to_list()\n",
    "    hypothesis_list = df['sentence2'].to_list()\n",
    "    label_list = df['gold_label'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usRpEcPWe7re",
    "outputId": "1300b6be-55c8-40fd-d4bb-bad1739834ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "mnli_dataset = MNLIDataAlbert(train_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "faJUFZc-hRrD"
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = mnli_dataset.get_data_loaders(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOdc4Cs2DEjt",
    "outputId": "c7e9663e-1ae0-4fa9-ffc9-6b5fcc69b306"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AlbertForSequenceClassification, AdamW\n",
    "\n",
    "model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=3)\n",
    "model.config.attention_probs_dropout_prob=0.\n",
    "model.config.hidden_dropout_prob=0.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "jxzpENXlEh-u"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "is1TqwTREid9"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FaW8zvjdUCLP",
    "outputId": "f02bab3e-5094-49a4-f8c0-6520adf9a1e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,685,891 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5vKtx05rXHLI"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "TsJ3tm74XtKF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer):  \n",
    "  total_step = len(train_loader)\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "     \n",
    "\n",
    "\n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_acc  = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "\n",
    "        # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "\n",
    "        print(pair_token_ids.size())\n",
    "        loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "        \n",
    "        # loss = criterion(prediction, labels)\n",
    "        acc = multi_acc(prediction, labels)\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_acc  += acc.item()\n",
    "        \n",
    "\n",
    "    val_acc  = total_val_acc/len(val_loader)\n",
    "    val_loss = total_val_loss/len(val_loader)\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drr2Y2eRY7op",
    "outputId": "36d6925c-56ed-4c1e-9eb4-839a63b050c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 48])\n",
      "Epoch 1: train_loss: 0.7541 train_acc: 0.5139 | val_loss: 0.8665 val_acc: 0.5714\n",
      "00:01:03.49\n",
      "torch.Size([7, 48])\n",
      "Epoch 2: train_loss: 0.8350 train_acc: 0.4444 | val_loss: 0.7825 val_acc: 0.4286\n",
      "00:00:52.46\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Sentence Entailment ALBERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
